{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Amiroodi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.7' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\Users\\Amiroodi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from going_modular.custom_data_setup_main_train import LoadDataset\n",
    "from going_modular import engine, utils\n",
    "from going_modular import custom_data_setup_pre_train\n",
    "from going_modular.OneHeadModel import OneHeadModel\n",
    "import helper_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "allow_train = False\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "shrink_size = None\n",
    "\n",
    "crop_size = 380\n",
    "\n",
    "num_augs = 0\n",
    "p_dropout = 0.3\n",
    "lr = 0.01\n",
    "weight_deacay = 1e-5\n",
    "T_max = 20\n",
    "eta_min = 1e-4\n",
    "momentum = 0.0\n",
    "\n",
    "freeze_encoder = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set matmul precision for TF32 usage on Ampere+ GPUs\n",
    "# torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = helper_functions.get_augmentation_train_transforms(num_augs, crop_size)\n",
    "test_transforms = helper_functions.get_augmentation_test_transforms(crop_size)\n",
    "no_transforms = helper_functions.get_augmentation_no_transforms(crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all dataloaders\n",
    "\n",
    "train_dataloader, class_names = custom_data_setup_pre_train.create_train_dataloader(\n",
    "    transform=train_transforms, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shrink_size=shrink_size) \n",
    "\n",
    "train_exp_dataloader, class_names = custom_data_setup_pre_train.create_train_dataloader(\n",
    "    transform=test_transforms,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shrink_size=shrink_size) \n",
    "\n",
    "val_dataloader, class_names = custom_data_setup_pre_train.create_test_dataloader(\n",
    "    transform=test_transforms, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shrink_size=shrink_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m test_dataset_no_transform \u001b[38;5;241m=\u001b[39m LoadDataset(APTOS_19_train_image_folder, APTOS_19_train_csv_file, transform\u001b[38;5;241m=\u001b[39mno_transforms)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 13\u001b[0m     img_2 \u001b[38;5;241m=\u001b[39m \u001b[43mtest_dataset_with_transform\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     14\u001b[0m     img_1 \u001b[38;5;241m=\u001b[39m test_dataset_no_transform[i][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     15\u001b[0m     fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32md:\\University Project\\DR_Project_Binary\\going_modular\\custom_data_setup_main_train.py:62\u001b[0m, in \u001b[0;36mLoadDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     59\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_folder, img_name) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     61\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[1;32m---> 62\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Apply transformations\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# plot some of the images to check applied augmentations\n",
    "\n",
    "IDRID_image_folder = \"../IDRID/Imagenes/Imagenes\" \n",
    "IDRID_csv_file = \"../IDRID/idrid_labels.csv\"  \n",
    "\n",
    "test_dataset_with_transform = LoadDataset(IDRID_image_folder, IDRID_csv_file, transform=train_transforms)\n",
    "test_dataset_no_transform = LoadDataset(IDRID_image_folder, IDRID_csv_file, transform=no_transforms)\n",
    "\n",
    "for i in range(2):\n",
    "    img_2 = test_dataset_with_transform[i][0].permute(1, 2, 0)\n",
    "    img_1 = test_dataset_no_transform[i][0].permute(1, 2, 0)\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    axes[0].imshow(img_1.numpy())\n",
    "    axes[1].imshow(img_2.numpy())\n",
    "    axes[0].axis(False)\n",
    "    axes[1].axis(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OneHeadModel(device=device, p_dropout=p_dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
    "if freeze_encoder:\n",
    "    for param in model.encoder.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "OneHeadModel (OneHeadModel)                                  [32, 3, 380, 380]    [32]                 --                   True\n",
       "├─Sequential (encoder)                                       [32, 3, 380, 380]    [32, 1792, 12, 12]   --                   True\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 380, 380]    [32, 48, 190, 190]   --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 380, 380]    [32, 48, 190, 190]   1,296                True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 48, 190, 190]   [32, 48, 190, 190]   96                   True\n",
       "│    │    └─SiLU (2)                                         [32, 48, 190, 190]   [32, 48, 190, 190]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 48, 190, 190]   [32, 24, 190, 190]   --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 48, 190, 190]   [32, 24, 190, 190]   2,940                True\n",
       "│    │    └─MBConv (1)                                       [32, 24, 190, 190]   [32, 24, 190, 190]   1,206                True\n",
       "│    └─Sequential (2)                                        [32, 24, 190, 190]   [32, 32, 95, 95]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 24, 190, 190]   [32, 32, 95, 95]     11,878               True\n",
       "│    │    └─MBConv (1)                                       [32, 32, 95, 95]     [32, 32, 95, 95]     18,120               True\n",
       "│    │    └─MBConv (2)                                       [32, 32, 95, 95]     [32, 32, 95, 95]     18,120               True\n",
       "│    │    └─MBConv (3)                                       [32, 32, 95, 95]     [32, 32, 95, 95]     18,120               True\n",
       "│    └─Sequential (3)                                        [32, 32, 95, 95]     [32, 56, 48, 48]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 32, 95, 95]     [32, 56, 48, 48]     25,848               True\n",
       "│    │    └─MBConv (1)                                       [32, 56, 48, 48]     [32, 56, 48, 48]     57,246               True\n",
       "│    │    └─MBConv (2)                                       [32, 56, 48, 48]     [32, 56, 48, 48]     57,246               True\n",
       "│    │    └─MBConv (3)                                       [32, 56, 48, 48]     [32, 56, 48, 48]     57,246               True\n",
       "│    └─Sequential (4)                                        [32, 56, 48, 48]     [32, 112, 24, 24]    --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 56, 48, 48]     [32, 112, 24, 24]    70,798               True\n",
       "│    │    └─MBConv (1)                                       [32, 112, 24, 24]    [32, 112, 24, 24]    197,820              True\n",
       "│    │    └─MBConv (2)                                       [32, 112, 24, 24]    [32, 112, 24, 24]    197,820              True\n",
       "│    │    └─MBConv (3)                                       [32, 112, 24, 24]    [32, 112, 24, 24]    197,820              True\n",
       "│    │    └─MBConv (4)                                       [32, 112, 24, 24]    [32, 112, 24, 24]    197,820              True\n",
       "│    │    └─MBConv (5)                                       [32, 112, 24, 24]    [32, 112, 24, 24]    197,820              True\n",
       "│    └─Sequential (5)                                        [32, 112, 24, 24]    [32, 160, 24, 24]    --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 112, 24, 24]    [32, 160, 24, 24]    240,924              True\n",
       "│    │    └─MBConv (1)                                       [32, 160, 24, 24]    [32, 160, 24, 24]    413,160              True\n",
       "│    │    └─MBConv (2)                                       [32, 160, 24, 24]    [32, 160, 24, 24]    413,160              True\n",
       "│    │    └─MBConv (3)                                       [32, 160, 24, 24]    [32, 160, 24, 24]    413,160              True\n",
       "│    │    └─MBConv (4)                                       [32, 160, 24, 24]    [32, 160, 24, 24]    413,160              True\n",
       "│    │    └─MBConv (5)                                       [32, 160, 24, 24]    [32, 160, 24, 24]    413,160              True\n",
       "│    └─Sequential (6)                                        [32, 160, 24, 24]    [32, 272, 12, 12]    --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 160, 24, 24]    [32, 272, 12, 12]    520,904              True\n",
       "│    │    └─MBConv (1)                                       [32, 272, 12, 12]    [32, 272, 12, 12]    1,159,332            True\n",
       "│    │    └─MBConv (2)                                       [32, 272, 12, 12]    [32, 272, 12, 12]    1,159,332            True\n",
       "│    │    └─MBConv (3)                                       [32, 272, 12, 12]    [32, 272, 12, 12]    1,159,332            True\n",
       "│    │    └─MBConv (4)                                       [32, 272, 12, 12]    [32, 272, 12, 12]    1,159,332            True\n",
       "│    │    └─MBConv (5)                                       [32, 272, 12, 12]    [32, 272, 12, 12]    1,159,332            True\n",
       "│    │    └─MBConv (6)                                       [32, 272, 12, 12]    [32, 272, 12, 12]    1,159,332            True\n",
       "│    │    └─MBConv (7)                                       [32, 272, 12, 12]    [32, 272, 12, 12]    1,159,332            True\n",
       "│    └─Sequential (7)                                        [32, 272, 12, 12]    [32, 448, 12, 12]    --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 272, 12, 12]    [32, 448, 12, 12]    1,420,804            True\n",
       "│    │    └─MBConv (1)                                       [32, 448, 12, 12]    [32, 448, 12, 12]    3,049,200            True\n",
       "│    └─Conv2dNormActivation (8)                              [32, 448, 12, 12]    [32, 1792, 12, 12]   --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 448, 12, 12]    [32, 1792, 12, 12]   802,816              True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1792, 12, 12]   [32, 1792, 12, 12]   3,584                True\n",
       "│    │    └─SiLU (2)                                         [32, 1792, 12, 12]   [32, 1792, 12, 12]   --                   --\n",
       "├─AdaptiveMaxPool2d (global_max_pool)                        [32, 1792, 12, 12]   [32, 1792, 1, 1]     --                   --\n",
       "├─AdaptiveAvgPool2d (global_avg_pool)                        [32, 1792, 12, 12]   [32, 1792, 1, 1]     --                   --\n",
       "├─BatchNorm1d (batch_norm_1)                                 [32, 1792]           [32, 1792]           3,584                True\n",
       "├─BatchNorm1d (batch_norm_2)                                 [32, 1792]           [32, 1792]           3,584                True\n",
       "├─Linear (dense1)                                            [32, 3584]           [32, 512]            1,835,520            True\n",
       "├─Sequential (classification_head)                           [32, 512]            [32, 1]              --                   True\n",
       "│    └─Linear (0)                                            [32, 512]            [32, 32]             16,416               True\n",
       "│    └─ReLU (1)                                              [32, 32]             [32, 32]             --                   --\n",
       "│    └─Dropout (2)                                           [32, 32]             [32, 32]             --                   --\n",
       "│    └─Linear (3)                                            [32, 32]             [32, 1]              33                   True\n",
       "============================================================================================================================================\n",
       "Total params: 19,407,753\n",
       "Trainable params: 19,407,753\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 140.61\n",
       "============================================================================================================================================\n",
       "Input size (MB): 55.45\n",
       "Forward/backward pass size (MB): 25331.50\n",
       "Params size (MB): 77.63\n",
       "Estimated Total Size (MB): 25464.58\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a summary using torchinfo (uncomment for actual output)\n",
    "torch.manual_seed(33)\n",
    "summary(\n",
    "model=model, \n",
    "input_size=(32, 3, crop_size, crop_size), # make sure this is \"input_size\", not \"input_shape\"\n",
    "col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "col_width=20,\n",
    "row_settings=[\"var_names\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "\n",
    "loss_fn_classification = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_deacay, momentum=momentum)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=T_max, eta_min=eta_min)\n",
    "\n",
    "# scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/pre_train_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m     utils\u001b[38;5;241m.\u001b[39msave_model(model\u001b[38;5;241m=\u001b[39mmodel, target_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_train_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/pre_train_model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Amiroodi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\Amiroodi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\Amiroodi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/pre_train_model.pth'"
     ]
    }
   ],
   "source": [
    "model = torch.compile(model)\n",
    "\n",
    "train_results = []\n",
    "\n",
    "if allow_train:\n",
    "    # Set the random seeds\n",
    "    torch.manual_seed(1404)\n",
    "    torch.cuda.manual_seed(1404)\n",
    "\n",
    "    # Start the timer\n",
    "    from timeit import default_timer as timer \n",
    "    start_time = timer()\n",
    "\n",
    "    # Setup training and save the results\n",
    "    train_results, val_results = engine.train(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loss_fn_classification=loss_fn_classification,\n",
    "        epochs=EPOCHS,\n",
    "        device=device)\n",
    "        \n",
    "    # End the timer and print out how long it took\n",
    "    end_time = timer()\n",
    "    print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n",
    "\n",
    "    utils.save_model(model=model, target_dir='models', model_name='pre_train_model.pth')\n",
    "else:\n",
    "    model.load_state_dict(torch.load('models/pre_train_model.pth', weights_only=True, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if allow_train:\n",
    "    helper_functions.plot_loss_curves(train_results, val_results)\n",
    "    helper_functions.plot_acc_curves(train_results, val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results is for APTOS-2019\n",
    "\n",
    "test_results = engine.test_step(\n",
    "    model=model,\n",
    "    dataloader=val_dataloader,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results is for APTOS-2015\n",
    "\n",
    "test_results = engine.test_step(\n",
    "    model=model,\n",
    "    dataloader=train_exp_dataloader,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_functions.plot_t_SNE(model=model,\n",
    "                        dataloader=val_dataloader,\n",
    "                        perp_vals=[5, 40],\n",
    "                        NUM_ITER=2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
